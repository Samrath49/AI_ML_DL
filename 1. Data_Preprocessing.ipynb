{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Data_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyKV/PEADCVP6pv4KdIJhQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samrath49/AI_ML_DL/blob/main/1.%20Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDUZ8ganeLUd"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_15eEW4MPBc"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j5_TN1Sepnf"
      },
      "source": [
        "## Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKVZgGk_eJyn"
      },
      "source": [
        "dataset = pd.read_csv('Data.csv')\r\n",
        "X = dataset.iloc[:,:-1].values\r\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnB67Jrzib61",
        "outputId": "07e4dafc-43fd-4506-f2a0-c03c610501c8"
      },
      "source": [
        "print(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]] ['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNk93BjyMz_4"
      },
      "source": [
        "## Taking Care of Missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aghz9MGti7P5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8ce39f-05d9-4071-e021-52a5287830f2"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\r\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'median')\r\n",
        "imputer.fit(X[:, 1:3])\r\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])\r\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 61000.0]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.0 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVbG5LVPNIkR"
      },
      "source": [
        "## Taking care of Categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8t8mZHoJ5FL",
        "outputId": "a66f4c2c-1268-446a-f7fc-0691447747e5"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "ct = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [0])], remainder= 'passthrough')\r\n",
        "X = np.array(ct.fit_transform(X))\r\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 1.0 0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 1.0 0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 1.0 0.0 40.0 61000.0]\n",
            " [1.0 0.0 1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 1.0 0.0 0.0 1.0 38.0 52000.0]\n",
            " [1.0 0.0 1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BZuW56sFR9O",
        "outputId": "2c1f345f-14a5-47a4-f69f-8f706211f70b"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "le = LabelEncoder()\r\n",
        "y = le.fit_transform(y)\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOP3L3OCNTlI"
      },
      "source": [
        "## Splitting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNUQdnoEGNdu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,  test_size= 0.2, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PA9zQBdHaak",
        "outputId": "1e383cd9-a803-47e9-8075-5e893ff6572a"
      },
      "source": [
        "print(X_train)\r\n",
        "print(X_test)\r\n",
        "print(y_train)\r\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 1.0 38.0 52000.0]\n",
            " [1.0 0.0 1.0 0.0 40.0 61000.0]\n",
            " [0.0 1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 0.0 48.0 79000.0]\n",
            " [1.0 0.0 1.0 0.0 50.0 83000.0]\n",
            " [0.0 1.0 0.0 0.0 35.0 58000.0]]\n",
            "[[1.0 0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 1.0 0.0 0.0 37.0 67000.0]]\n",
            "[0 1 0 0 1 1 0 1]\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAumoC8NMTkb"
      },
      "source": [
        "## Feature Scaling \r\n",
        "\r\n",
        "Applied coz some features might dominate other features and hence the dominated once will not perform better. Hence using it we balance the features importance.\r\n",
        "\r\n",
        "Two techiques to do it is:\r\n",
        "\r\n",
        "Standardization- Makes feature in range of -3 to +3.  Used all the time.\r\n",
        "\r\n",
        "Normalization- Turns features in 0 or 1. Used for normal distributions only.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6XnaCjxIy8z"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "sc = StandardScaler()\r\n",
        "# We never apply feature scalling on dummy variables. For eg on Country name.\r\n",
        "X_train[:, 3: ] = sc.fit_transform(X_train[:, 3:]) #sc_fit computes sd and mean of column and transform use that values to generate standardization\r\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:]) # We don't use fit since we don't ever want to have new values for our test set as it should use mean and sd of train set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qdyz2uPSCVT",
        "outputId": "e5a9f388-3fcb-441d-8146-7c7ce3a56588"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 1.2909944487358058 -0.28942984211696865 -1.0430254692900243]\n",
            " [1.0 0.0 1.0 -0.7745966692414834 0.0 -0.2767210428728636]\n",
            " [0.0 1.0 0.0 -0.7745966692414834 0.5788596842339373 0.659873256081444]\n",
            " [1.0 0.0 0.0 1.2909944487358058 -0.28942984211696865 -0.2767210428728636]\n",
            " [1.0 0.0 0.0 1.2909944487358058 -1.8812939737602963 -1.383605214364318]\n",
            " [0.0 1.0 0.0 -0.7745966692414834 1.1577193684678746 1.2558878099614579]\n",
            " [1.0 0.0 1.0 -0.7745966692414834 1.4471492105848434 1.5964675550357514]\n",
            " [0.0 1.0 0.0 -0.7745966692414834 -0.7235746052924217 -0.5321558516785838]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9a--qtLS0P5"
      },
      "source": [
        "#### Why not to use fit on X_test\r\n",
        "X_test[:, 3:] = sc.fit_transform(X_test[:, 3:]) this gives us wrong test feature scalling as:\r\n",
        "~~~\r\n",
        "print(X_test)\r\n",
        "[[1.0 0.0 1.0 0.0 -1.0 -1.0]\r\n",
        " [0.0 1.0 0.0 0.0 1.0 1.0]]\r\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkg3E0oiSEH_",
        "outputId": "5fe02a10-ddee-4a11-b86f-83594d16dd2e"
      },
      "source": [
        "print(X_test) # correct feature scalling"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 1.0 -2.775557561562892e-17 -1.0 -1.0]\n",
            " [0.0 1.0 0.0 -2.775557561562892e-17 1.0 1.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}